# CNN_Gesture 一个实时的手势识别脚本

基于Opencv+keras的实时手势识别系统，准确率约96%，可录制数据集。

python3.6 + opencv + keras + numpy + PIL  
  
运行"录制手势.py"，点击opencv的窗口, 如果发现背景不够干净可以通过键盘按'b'重置背景.

键盘按'l'进入手势录制模式，一个手势录制完训练集后会阻塞 3s，再开始录制测试集。
每个手势训练集+测试集录制结束后，键盘再按'l'会录制下一个手势，直到所有手势都录制完成。
 
全部训练手势录制完,按't'进行训练，模型训练结束会得到一下内容
* 模型的结构图
* 训练集和测试集的准确率和损失折线图
* 测试集的混淆矩阵图
* .h5 后缀的模型
  
training.py 如果已经含有数据集或者使用上传的数据集，可以直接运行得到模型  
predict.py 可以查看每个手势的预测准确率
 
获得模型后，预测手势需要进行如下步骤：
1. 运行"录制手势.py"
2. 等待 Opencv 窗口弹出
3. 点击窗口名为 'thresh' 的窗口，按下'p'键，在控制台输入模型的名字, 等待模型加载。
   调整摄像头位置，保持'thresh' 窗口内蓝色矩形区域背景干净，按'b'键可重置背景，将手伸到的矩形范围内，
   矩形上方红色字体表示对于的正确手势
